{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,  FunctionTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RandomizedSearchCV\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import cloudpickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c267cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'classification_package'\n",
    "\n",
    "file_path = os.path.join(\"qws1\",\"data.csv\")\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "X = df.drop(columns='Class')\n",
    "Y = df['Class']\n",
    "\n",
    "X_rest, X_test, Y_rest, Y_test = train_test_split(X, Y, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "if X_rest is not None and X_test is not None:\n",
    "    joblib.dump(X_rest, os.path.join(save_path, 'X_rest.pkl'))\n",
    "    joblib.dump(X_test, os.path.join(save_path, 'X_test.pkl'))\n",
    "    \n",
    "if Y_rest is not None and Y_test is not None:\n",
    "    joblib.dump(Y_rest, os.path.join(save_path, 'Y_rest.pkl'))\n",
    "    joblib.dump(Y_test, os.path.join(save_path, 'Y_test.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc92e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num_passthrough__Availability', 'num_passthrough__Throughput',\n",
      "       'num_passthrough__Successability', 'num_passthrough__Reliability',\n",
      "       'num_passthrough__Compliance', 'num_passthrough__Documentation',\n",
      "       'cat_to_numeric__0_0', 'cat_to_numeric__0_1', 'cat_to_numeric__0_2',\n",
      "       'cat_to_numeric__0_3', 'cat_to_numeric__0_4', 'cat_to_numeric__0_5',\n",
      "       'cat_to_numeric__0_6', 'cat_to_numeric__0_7', 'cat_to_numeric__0_8'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asaraiva\\AppData\\Local\\Temp\\ipykernel_14580\\974180610.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  z_scores = (X_used[:, col] - mean_val) / std_val\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Original feature lists\n",
    "numeric_features = ['Availability', 'Throughput', 'Successability',\n",
    "                    'Reliability', 'Compliance', 'Documentation']\n",
    "categorical_features = ['Service Name']\n",
    "\n",
    "# --- Custom Winsorizer function ---\n",
    "def winsorize(X_ori):\n",
    "\n",
    "    threshold = 3\n",
    "    X_used = X_ori.copy()\n",
    "\n",
    "    for col in range(X_used.shape[1]):\n",
    "        Q1 = np.percentile(X_used[:, col], 25)\n",
    "        Q3 = np.percentile(X_used[:, col], 75)\n",
    "        lower = Q1 - 1.5 * (Q3 - Q1)\n",
    "        upper = Q3 + 1.5 * (Q3 - Q1)\n",
    "\n",
    "        # Clip extremes\n",
    "        X_used[:, col] = np.clip(X_used[:, col], lower, upper)\n",
    "\n",
    "        # Z-score check\n",
    "        mean_val = X_used[:, col].mean()\n",
    "        std_val = X_used[:, col].std()\n",
    "        z_scores = (X_used[:, col] - mean_val) / std_val\n",
    "        mask = np.abs(z_scores) < threshold\n",
    "        median_val = np.median(X_used[:, col])\n",
    "        X_used[:, col] = np.where(mask, X_used[:, col], median_val)\n",
    "\n",
    "    return X_used\n",
    "\n",
    "\n",
    "winsorizer = FunctionTransformer(winsorize, validate=False)\n",
    "\n",
    "\n",
    "cats_to_numeric = Pipeline(steps=[\n",
    "    (\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", BinaryEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ColumnDropperByName(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, patterns=None):\n",
    "        self.patterns = patterns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            self.feature_names_ = X.columns.tolist()\n",
    "        else:\n",
    "            self.feature_names_ = None\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.feature_names_)\n",
    "        if self.patterns:\n",
    "            drop_cols = [col for col in X.columns if any(col.endswith(p) for p in self.patterns)]\n",
    "            X = X.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "        return X.values\n",
    "\n",
    "\n",
    "pre_as_numeric = ColumnTransformer(transformers=[\n",
    "    (\"num_passthrough\", \"passthrough\", numeric_features),\n",
    "    (\"cat_to_numeric\", cats_to_numeric, categorical_features),\n",
    "], remainder=\"drop\", sparse_threshold=0.0)\n",
    "\n",
    "\n",
    "def to_dataframe(X):\n",
    "    # Get feature names from ColumnTransformer\n",
    "    feature_names = pre_as_numeric.get_feature_names_out()\n",
    "    return pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "as_dataframe = FunctionTransformer(to_dataframe, validate=False)\n",
    "\n",
    "\n",
    "\n",
    "pipeline_all = Pipeline(steps=[\n",
    "    (\"to_numeric\", pre_as_numeric),\n",
    "    (\"as_dataframe\", as_dataframe),\n",
    "    (\"drop_cols\", ColumnDropperByName(patterns=['_4','_5','_6','_7','_8'])),\n",
    "    (\"winsorizer\", winsorizer),\n",
    "    (\"imputer_median\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_all.fit(X_rest)\n",
    "\n",
    "#print(pre_as_numeric.get_feature_names_out())\n",
    "print(pipeline_all.named_steps['as_dataframe'].transform(pre_as_numeric.transform(X_rest)).columns)\n",
    "\n",
    "\n",
    "# Save\n",
    "with open(os.path.join(save_path, 'preprocessor.pkl'), 'wb') as f:\n",
    "    cloudpickle.dump(pipeline_all, f)\n",
    "\n",
    "#joblib.dump(pipeline_all, os.path.join(save_path, 'preprocessor.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Original feature lists\n",
    "numeric_features = ['Availability', 'Throughput', 'Successability',\n",
    "                    'Reliability', 'Compliance', 'Documentation']\n",
    "categorical_features = ['Service Name']\n",
    "\n",
    "# --- Custom Winsorizer function ---\n",
    "def winsorize(X_ori):\n",
    "\n",
    "    threshold = 3\n",
    "    X_used = X_ori.copy()\n",
    "\n",
    "    for col in range(X_used.shape[1]):\n",
    "        Q1 = np.percentile(X_used[:, col], 25)\n",
    "        Q3 = np.percentile(X_used[:, col], 75)\n",
    "        lower = Q1 - 1.5 * (Q3 - Q1)\n",
    "        upper = Q3 + 1.5 * (Q3 - Q1)\n",
    "\n",
    "        # Clip extremes\n",
    "        X_used[:, col] = np.clip(X_used[:, col], lower, upper)\n",
    "\n",
    "        # Z-score check\n",
    "        mean_val = X_used[:, col].mean()\n",
    "        std_val = X_used[:, col].std()\n",
    "        z_scores = (X_used[:, col] - mean_val) / std_val\n",
    "        mask = np.abs(z_scores) < threshold\n",
    "        median_val = np.median(X_used[:, col])\n",
    "        X_used[:, col] = np.where(mask, X_used[:, col], median_val)\n",
    "\n",
    "    return X_used\n",
    "\n",
    "\n",
    "winsorizer = FunctionTransformer(winsorize, validate=False)\n",
    "\n",
    "\n",
    "cats_to_numeric = Pipeline(steps=[\n",
    "    (\"imputer_cat\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", BinaryEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnDropperByName(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, drop_names=None):\n",
    "        self.drop_names = drop_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # If X is numpy, convert to DataFrame with generic names\n",
    "        \n",
    "        if self.drop_names:\n",
    "            X = X.drop(columns=self.drop_names, errors='ignore')\n",
    "        return X\n",
    "\n",
    "# --- Step 2: Combine numeric + encoded categorical ---\n",
    "pre_as_numeric = ColumnTransformer(transformers=[\n",
    "    (\"num_passthrough\", \"passthrough\", numeric_features),\n",
    "    (\"cat_to_numeric\", cats_to_numeric, categorical_features),\n",
    "], remainder=\"drop\", sparse_threshold=0.0)\n",
    "\n",
    "def to_dataframe(X):\n",
    "    # Get feature names from ColumnTransformer\n",
    "    feature_names = pre_as_numeric.get_feature_names_out()\n",
    "    return pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "as_dataframe = FunctionTransformer(to_dataframe, validate=False)\n",
    "\n",
    "pipeline_all = Pipeline(steps=[\n",
    "    (\"to_numeric\", pre_as_numeric),\n",
    "    (\"as_dataframe\", as_dataframe),\n",
    "    (\"drop_cols\", ColumnDropperByName(drop_names=['cat_to_numeric__encoder__0_4',\n",
    "                                                  'cat_to_numeric__encoder__0_5',\n",
    "                                                  'cat_to_numeric__encoder__0_6',\n",
    "                                                  'cat_to_numeric__encoder__0_7',\n",
    "                                                  'cat_to_numeric__encoder__0_8'])),\n",
    "    (\"winsorizer\", winsorizer),\n",
    "    (\"imputer_median\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "# Fit pipeline\n",
    "pipeline_all.fit(X_rest)\n",
    "\n",
    "print(pre_as_numeric.get_feature_names_out())\n",
    "\n",
    "# Save pipeline\n",
    "joblib.dump(pipeline_all, os.path.join(save_path, 'preprocessor.pkl'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
